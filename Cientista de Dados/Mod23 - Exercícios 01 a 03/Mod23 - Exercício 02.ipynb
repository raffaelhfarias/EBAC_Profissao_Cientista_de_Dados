{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645ed2d1",
   "metadata": {},
   "source": [
    "# Módulo 23 - Tarefa 02\n",
    "1. Monte um passo a passo para o algoritmo Random Forest\n",
    "2. xplique com suas palavras o Random Forest\n",
    "3. Qual a diferença entre Bagging e Random Forest?\n",
    "\n",
    "\n",
    "### Random Forest\n",
    "Assim como o Bagging, Random Forest também é um método de aprendizagem em conjunto (Ensemble Learning) para classificações, regressões e algumas outras tarefas e funciona construindo várias árvores de decisão.\n",
    "<br>\n",
    "Normalmente uma árvore de decisão com grande profundidade tende a aprender padrões irregulares e acaba ocorrendo overfitting com a base de treino. O Random Forest é uma maneira de calcular uma média de várias árvores com grande profundidade treinadas em diferentes partes do mesmo conjunto de treinamento, com o objetivo de reduzir a variância.\n",
    "\n",
    "## Passo a passo:\n",
    "\n",
    "### Feature Bagging\n",
    "O algoritmo de treinamento para a Random Forest aplica a técnica geral do Bootstrap Aggregating (Bagging) com uma pequena modificação dividindo também as colunas com as variáveis explicativas do modelo.\n",
    "<br>\n",
    "Dado uma base treinamento $D$ com $p$ colunas de variáveis explicativas $X_i$ e uma coluna com a variável resposta $Y$, iremos gerar $m$ novas bases de dados $D_i$ com $\\sqrt[2]{p}$ (arredondado para baixo) colunas de variáveis explicativas para um problema de classificação ou  $p/3$ (arredondado para baixo) colunas de variáveis explicativas para um problema de regressão, recomenda-se também um tamanho mínimo de nó de valor 5.\n",
    "<br>\n",
    "As colunas de variáveis explicativas devem ser selecionadas aleatóriamente e as linhas para as novas bases de dados de treino devem ser selecionadas da base de treino original de maneira aleatóriamente e com reposição.\n",
    "\n",
    "### Modelagem\n",
    "\n",
    "Depois de criadas as bases de treino $D_i$ aplicamos o método de aprendizado de árvore (Árvore de Decisão) a cada uma das $m$ bases de treino $D_i$.\n",
    "\n",
    "### Resultado\n",
    "\n",
    "Depois de ajustarmos $m$ modelos utilizando as $m$ amostras obtidas no Feature Bagging, combinamos os resultados por sua média (para modelos de regressão) ou por votação (para modelos de classificação).\n",
    "\n",
    "### Diferença entre Bagging e Random Forest\n",
    "\n",
    "Random Forest é focado em utilizarmos modelos de Árvore de Decisão, já o Bagging é mais aberto a outros modelos, por exemplo os de regressão linear ou logistica.\n",
    "Na hora de separar a base de treino inicial o Bagging leva em conta apenas as linhas, já o Random Forest utiliza também uma separação nas colunas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
